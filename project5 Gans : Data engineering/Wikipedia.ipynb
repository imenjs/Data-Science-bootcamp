{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cc983ed-2bc6-4a24-af51-e4e39a6d5c8a",
   "metadata": {},
   "source": [
    "import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7c7f4-99a9-450b-b1fc-56b19823aa8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6d7fe-b932-4691-85ba-10eafa97a222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4e80aed-7ae5-4106-99f0-0576d48202ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cbaef1-3b5f-49fa-9d89-5e8c93fa124b",
   "metadata": {},
   "source": [
    "Function to fetch HTML content of a Wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a5100132-8cd5-4037-9060-a71b5764bd09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_wikipedia_html(city):\n",
    "    url = f\"https://en.wikipedia.org/wiki/{city}\"\n",
    "    Web_page = requests.get(url)\n",
    "    return Web_page.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803528e-d19b-4a0d-a84e-fac8ac119b37",
   "metadata": {},
   "source": [
    "Population function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4441fd35-6390-4f75-9b3e-b57190e0f365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#original \n",
    "# Function to extract population from HTML\n",
    "def extract_population(html_doc):\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    # Find all paragraph tags\n",
    "    paragraphs = soup.find_all('p')\n",
    "    # Iterate over paragraphs to find population information\n",
    "    for p in paragraphs:\n",
    "        if 'population' in p.text.lower() or 'inhabitants' in p.text.lower():\n",
    "            # Extract population value using regular expression\n",
    "            population_matches = re.findall(r'\\b(\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)(?=\\s*million|\\s*inhabitants|\\s*residents)\\s*(?:million)?\\s*(?:inhabitants)?\\s*(?:residents)?\\b', p.text)\n",
    "           # population_matches = re.findall(r'\\b(?:population\\s+of\\s+over|population\\s+of|\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?)\\s*(?=\\s*million|\\s*inhabitants|\\s*residents)?(?:\\s*million|\\s*inhabitants|\\s*residents)?\\b', p.text)\n",
    "\n",
    "            if population_matches:\n",
    "                # Check if the population contains commas\n",
    "                population_with_commas = population_matches[0]\n",
    "                if ',' in population_with_commas:\n",
    "                    # Remove commas and convert to float, then divide by million\n",
    "                    population_no_commas = population_with_commas.replace(',', '')\n",
    "                    return float(population_no_commas) / 1e6  # Divide by 1 million to get the value in millions\n",
    "                else:\n",
    "                    return float(population_with_commas)  # Return the population as float\n",
    "    # If population information not found\n",
    "    return float('nan')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aace02d-e96c-4ecc-9a6b-8a911d612267",
   "metadata": {},
   "source": [
    "Country function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69bc8b6c-637a-4f49-87ad-9bc8ee8efd6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_country_name(html_doc):\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    # Find the infobox table\n",
    "    infobox = soup.find('table', class_='infobox')\n",
    "    # Search for the country name within the infobox\n",
    "    if infobox:\n",
    "        country_cell = infobox.find('th', string='Country')\n",
    "        if country_cell:\n",
    "            # Get the following cell as the country name\n",
    "            country_name = country_cell.find_next('td').get_text().strip()\n",
    "            return country_name\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932b46c-c8d6-41d2-a10d-25b115f34ef5",
   "metadata": {},
   "source": [
    "Year Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b9a69cf-e844-46ff-9bba-ac1922430e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_year(html_doc):\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    # Find all rows in the infobox\n",
    "    rows = soup.select('table.infobox.ib-settlement.vcard tr')\n",
    "    \n",
    "    # Initialize row number\n",
    "    row_number = None\n",
    "    \n",
    "    # Iterate over rows to find the one containing population information\n",
    "    for i, row in enumerate(rows):\n",
    "        if 'population' in row.text.lower():\n",
    "            row_number = i + 1  # Adjust row number to 1-indexed\n",
    "            break\n",
    "    \n",
    "    # If population row is found, extract year from the same row\n",
    "    if row_number:\n",
    "        year_element = soup.select_one(f'table.infobox.ib-settlement.vcard tr:nth-of-type({row_number}) th div')\n",
    "        if year_element:\n",
    "            year_text = year_element.get_text(strip=True)\n",
    "            pattern = r'(\\d{4})'\n",
    "            match = re.search(pattern, year_text)\n",
    "            if match:\n",
    "                return match.group(1)\n",
    "    \n",
    "    return \"Year information not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5fd93-d9f5-4c77-9f96-0694b15cfcf9",
   "metadata": {},
   "source": [
    "Coordonate Function and split into 2 float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11ab6309-a5d2-4d32-8930-9baf69b8c9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_coordinates(html_doc):\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    # Find infobox\n",
    "    infobox = soup.find('table', class_='infobox')\n",
    "    if infobox:\n",
    "        # Find rows in infobox\n",
    "        rows = infobox.find_all('tr')\n",
    "        for row in rows:\n",
    "            # Check if row contains 'Coordinates' or similar text\n",
    "            if 'coordinates' in row.text.lower():\n",
    "                # Extract coordinates from the row\n",
    "                coordinates = row.find('span', class_='geo').text\n",
    "                # Split coordinates into latitude and longitude\n",
    "                lat, lon = map(float, coordinates.split(';'))\n",
    "                return lat, lon\n",
    "    # If coordinates not found\n",
    "    return float('nan'), float('nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11172c9-19f0-412e-8103-378bb4b7beeb",
   "metadata": {},
   "source": [
    "create table city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7fdb4bec-6fbc-4861-8012-b2b54c669b34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "city_list = ['Munich', 'Berlin', 'Cologne', 'Hamburg', 'Frankfurt','Leipzig' , \"Hannover\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "city = pd.DataFrame(city_list, columns=['city'])\n",
    "#print(City)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5bc25c75-4f90-4995-acc2-2d907bc2f696",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Munich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cologne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Leipzig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hannover</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city\n",
       "0     Munich\n",
       "1     Berlin\n",
       "2    Cologne\n",
       "3    Hamburg\n",
       "4  Frankfurt\n",
       "5    Leipzig\n",
       "6   Hannover"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7975a0-4e79-427b-b0b9-afeef5d8efa1",
   "metadata": {},
   "source": [
    "# Create the generale data frame with all collumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10316101-9d3b-454a-baec-83aa5593043b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City  Country  Population (million)  Year  Latitude  Longitude\n",
      "0     Munich  Germany              1.578132  2022  48.13750   11.57500\n",
      "1     Berlin  Germany              3.850000  2024  52.52000   13.40500\n",
      "2    Cologne  Germany              1.100000  2021  50.93639    6.95278\n",
      "3    Hamburg  Germany              1.900000  2022  53.55000   10.00000\n",
      "4  Frankfurt  Germany              0.791000  2022  50.11056    8.68222\n",
      "5    Leipzig  Germany              0.628718  2021  51.34000   12.37500\n",
      "6   Hannover  Germany              1.160000  2021  52.36700    9.71700\n",
      "7      Paris   France              2.102650  2023  48.85667    2.35222\n",
      "8  Barcelona    Spain              1.600000  2018  41.38278    2.17694\n"
     ]
    }
   ],
   "source": [
    "# Function to get population, year ,coordinates, and country name for a city\n",
    "def get_city_info(city):\n",
    "    # Fetch HTML content of the Wikipedia page for the city\n",
    "    html_doc = get_wikipedia_html(city)\n",
    "    \n",
    "    # Extract population for the city\n",
    "    population = extract_population(html_doc)\n",
    "    \n",
    "    # Extract coordinates for the city\n",
    "    latitude, longitude = extract_coordinates(html_doc)\n",
    "    \n",
    "    # Extract country name for the city\n",
    "    country_name = extract_country_name(html_doc)\n",
    "    \n",
    "    year_population = extract_year(html_doc)\n",
    "    \n",
    "    return city, country_name, population,year_population, latitude, longitude\n",
    "\n",
    "# List of cities\n",
    "cities = ['Munich', 'Berlin', 'Cologne', 'Hamburg', 'Frankfurt','Leipzig' , \"Hannover\", \"Paris\",\"Barcelona\"]\n",
    "\n",
    "# Create a list to store city information\n",
    "city_info = []\n",
    "\n",
    "# Get information for each city and store it in the list\n",
    "for city in cities:\n",
    "    city_info.append(get_city_info(city))\n",
    "\n",
    "# Create a DataFrame from the city information\n",
    "city_df = pd.DataFrame(city_info, columns=['City', 'Country', 'Population (million)', \"Year\",'Latitude', 'Longitude'])\n",
    "print(city_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99100f2a-f46f-4100-bcb2-fd5aae904c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city_df['Year'] = pd.to_datetime(city_df['Year'], format='%Y')\n",
    "city_df['Year'] = city_df['Year'].dt.strftime('%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9df1eb-d966-4b0e-95bf-17d3fcdb673a",
   "metadata": {},
   "source": [
    "Create table population with cityname, city population , and year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa21b04f-56fa-4072-9851-d0969af9320c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City  Population (million)  Year\n",
      "0     Munich              1.578132  2022\n",
      "1     Berlin              3.850000  2024\n",
      "2    Cologne              1.100000  2021\n",
      "3    Hamburg              1.900000  2022\n",
      "4  Frankfurt              0.791000  2022\n",
      "5    Leipzig              0.628718  2021\n",
      "6   Hannover              1.160000  2021\n"
     ]
    }
   ],
   "source": [
    "def get_city_info(city):\n",
    "    # Fetch HTML content of the Wikipedia page for the city\n",
    "    html_doc = get_wikipedia_html(city)\n",
    "    \n",
    "    # Extract population for the city\n",
    "    population = extract_population(html_doc)\n",
    "    \n",
    "   \n",
    "    year_population = extract_year(html_doc)\n",
    "    \n",
    "    return city, population,year_population\n",
    "\n",
    "# List of cities\n",
    "cities = ['Munich', 'Berlin', 'Cologne', 'Hamburg', 'Frankfurt','Leipzig' , \"Hannover\"]\n",
    "\n",
    "# Create a list to store city information\n",
    "city_info = []\n",
    "\n",
    "# Get information for each city and store it in the list\n",
    "for city in cities:\n",
    "    city_info.append(get_city_info(city))\n",
    "\n",
    "# Create a DataFrame from the city information\n",
    "population_df = pd.DataFrame(city_info, columns=['City', 'Population (million)', \"Year\"])\n",
    "print(population_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ce71f-f179-42ef-b2c0-f7ad48d7be71",
   "metadata": {},
   "source": [
    "create table Geo with city country , longitude and largitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dcf96237-8300-4354-82a4-6a7642e1215c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City  Country  Latitude  Longitude\n",
      "0     Munich  Germany  48.13750   11.57500\n",
      "1     Berlin  Germany  52.52000   13.40500\n",
      "2    Cologne  Germany  50.93639    6.95278\n",
      "3    Hamburg  Germany  53.55000   10.00000\n",
      "4  Frankfurt  Germany  50.11056    8.68222\n",
      "5    Leipzig  Germany  51.34000   12.37500\n",
      "6   Hannover  Germany  52.36700    9.71700\n"
     ]
    }
   ],
   "source": [
    "# Function to get population, year ,coordinates, and country name for a city\n",
    "def get_city_info(city):\n",
    "    # Fetch HTML content of the Wikipedia page for the city\n",
    "    html_doc = get_wikipedia_html(city)\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Extract coordinates for the city\n",
    "    latitude, longitude = extract_coordinates(html_doc)\n",
    "    \n",
    "    # Extract country name for the city\n",
    "    country_name = extract_country_name(html_doc)\n",
    "  \n",
    "    \n",
    "    return city, country_name,  latitude, longitude\n",
    "\n",
    "# List of cities\n",
    "cities = ['Munich', 'Berlin', 'Cologne', 'Hamburg', 'Frankfurt','Leipzig' , \"Hannover\"]\n",
    "\n",
    "# Create a list to store city information\n",
    "city_info = []\n",
    "\n",
    "# Get information for each city and store it in the list\n",
    "for city in cities:\n",
    "    city_info.append(get_city_info(city))\n",
    "\n",
    "# Create a DataFrame from the city information\n",
    "\n",
    "geo_df = pd.DataFrame(city_info, columns=['City', 'Country','Latitude', 'Longitude'])\n",
    "print(geo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d83127-e001-4870-8168-06080eacda53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "population_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a0a5b1c-6ee3-43c9-b29c-6dd1c0f02e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "population_df['Year'] = population_df['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abd80374-31eb-4196-b305-11d744ab8ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "population_df = population_df.rename(columns={'Population (million)': 'population_million'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb5a42a-7006-49e9-b6e1-95d901580b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geo_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad2216-e536-4719-855b-b71b301c4502",
   "metadata": {},
   "source": [
    "Connection with my sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07523cc9-e32c-423b-bb88-b626286a887d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = \"sql_workshop\"\n",
    "host = \"127.0.0.1\"\n",
    "user = \"root\"\n",
    "password = \"password\"\n",
    "port = 3306\n",
    "\n",
    "connection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecde4a0-55d5-40d3-8542-b95096bbe47b",
   "metadata": {},
   "source": [
    "push the table to my sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9005089-79d4-4243-8ae3-c4d0fa8f93fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "population_df.to_sql('population_df',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd011c65-748b-44d8-8a29-fb1555619a59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df.to_sql('geo_df',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ae30312-314f-4fda-97c9-ed92d7243d79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.to_sql('city',\n",
    "                  if_exists='append',\n",
    "                  con=connection_string,\n",
    "                  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
